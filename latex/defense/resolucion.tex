\section{Algoritmo}
\begin{frame}{Resolución}

Una vez fijado el modelo, una manera de resolver un problema de programación lineal entera consiste en aplicar un algoritmo de \textit{branch and cut}, el cual es una combinación de las técnicas de \alert<2>{planos de corte} y de \alert<3>{branch and bound}.
\vskip 5pt
\uncover<2->{La primera se basa en resolver el problema de programación lineal \textbf{sin} las restricciones de integralidad, eliminar la solucción fraccionaria con algún criterio, y repetir el proceso hasta llegar a una solución óptima entera.}
\vskip 5pt
\uncover<3->{La segunda subdivide el problema sucesivamente en otros más pequeños, eliminando ciertas soluciones fraccionarias, y manteniendo durante el recorrido del árbol generado una cota superior y otra inferior para el óptimo buscado.}

\end{frame} 

\begin{frame}{Componentes}

Un algoritmo de branch and cut consta entonces, de los siguientes componentes:

\begin{itemize}
\item<2->{\textbf{Algoritmos de separación}, para remover soluciones fraccionales aplicando planos de corte construidos a partir de desigualdades válidas}
\item<3->{\textbf{Estrategias de branching}, para decidir con qué criterio se subdivide el problema a cada nodo del árbol}
\item<4->{\textbf{Heurísticas inicial y primal}, para contar con soluciones enteras factibles durante el recorrido del árbol, que actúan como cotas superiores para el óptimo.}
\end{itemize}

\end{frame} 

\subsection{Planos de corte}

\begin{frame} 
\frametitle{Desigualdades válidas para PCP}

\begin{itemize}

\item{En una clique extendida, cada nodo debe tener un color distinto.
\lpineq{\sum_{i \in K} x_{ij_0} \leq w_{j_0}}{\forall j_0 \in C}
\extclique
\uncover<2>{Usamos un algoritmo goloso basado en los valores de las variables y los grados de los nodos para construir los planos de corte correspondientes.}
}

\end{itemize}

\end{frame} 


\begin{frame} 
\frametitle{Desigualdades válidas para PCP}

\begin{itemize}

\item{Una partición no puede colorearse con el color $j_0$ a menos que todos los anteriores ya hayan sido usados.
\lpineq{\sum_{i \in p_0}\sum_{j \geq j_0} x_{ij} \leq w_{j_0}}{\forall p_0 \in P, j_0 \in C}}

\uncover<2->{
Hay solamente $|P| \times |C|$, con lo que pueden resolverse mediante simple enumeración.
}

\end{itemize}

\end{frame} 

\begin{frame} 
\frametitle{Desigualdades válidas para PCP}

\begin{itemize}

\item{Dado un conjunto independiente máximo $I$ de tamaño $\alpha$ tal que cada nodo está en una partición distinta, a lo sumo $\alpha$ nodos pueden tener el mismo color.
\lpineq{\sum _{i \in I} x_{ij_0} \leq \alpha w_{j_0}}{\forall j_0 \in C}

\uncover<2->{
Especializamos esta desigualdad tomando subgrafos cuyos conjunto independientes máximos son fáciles de calcular.

\begin{itemize}
\item{Component paths}
\item{Component holes}
\end{itemize}
}

\uncover<3->{Nuevamente usamos un algoritmo goloso para construir estos planos de corte, acotando la cantidad de veces que cada nodo y cada eje puede ser visitado.}}

\end{itemize}
\end{frame} 

\begin{frame} 
\frametitle{Desigualdades válidas para PCP}

\begin{itemize}

\item Dado un grafo, definimos su \textit{grafo de particiones} como un grafo que tiene un nodo por cada partición del original, y dos nodos son adyacentes sii todos los nodos de las dos particiones eran adyacentes entre sí:
\uncover<2->{
	\alt<2>
	{\togprime}
	{\gprime}
}

\uncover<4->{Las desigualdades de conjunto independiente se pueden aplicar sobre el grafo de particiones y llevarse al grafo original.}
\vfill
\end{itemize}

\end{frame} 

\begin{frame} 
\frametitle{Planos de corte}

Analizamos el gap en grafos de distinta densidad al aplicar distintas familias de corte sobre los ya provistos por \textsc{cplex} en un algoritmo de planos de corte:

\includechart{chartcuts.png}

\end{frame} 

\subsection{Estrategia de branching}

\begin{frame}{Estrategia de Branching}

Lo siguiente es definir una estrategia de branching, que determina cómo generar los subproblemas a partir de un nodo del árbol.
\vskip 3pt
\uncover<2->{Las estrategias típicas son tomar la variable con valor más fraccionario o menos fraccionario en la solución de la relajación, y forzar a que tome valor $0$ o $1$ en cada hijo.
\begin{figure}[h]
	\centering
	\branchingtree
\end{figure}
}
\end{frame} 

\begin{frame}{Estrategia de Branching en PCP}

En PCP usamos como criterio de branching seleccionar un nodo de una partición sin colorear y asignarle un color distinto entre todos los posibles en los subproblemas:

\begin{figure}[h]
	\centering
	\pcpbranchingtree
\end{figure}

\uncover<2->{El nodo elegido a colorear es el que tiene mayor grado de saturación, es decir, distintos colores usados para sus vecinos.}

\end{frame} 

\begin{frame}{Estrategia de Branching en PCP}

Comparando contra las otras estrategias en grafos de distinta densidad en un branch and bound:

\includechart{chartbranchingstrategy.png}

\end{frame} 

\subsection{Heurísticas Primal e Inicial}

\begin{frame}{Heurísticas}

La heurística primal se utiliza para generar soluciones enteras a lo largo del algoritmo, que actúan como cota superior para el óptimo.

Una heurística usual consiste en redondear las variables de acuerdo a su valor fraccionario en la relajación para llegar a una solución entera.

\uncover<2>{Nosotros adaptamos algoritmos existentes de coloreo a este problema para utilizar como heurísticas.}

\end{frame}

\begin{frame}{Algoritmos de enumeración}

En coloreo, un algoritmo de enumeración recorre posibles coloreos, eliminando gran cantidad de soluciones simétricas y podando aquellos que no logran un valor mejor al alcanzado hasta el momento.

En cada iteración, se elige un nodo y se intenta colorearlo con los colores disponibles.

\uncover<2->{Distintos criterios para elegir el nodo a colorear dan lugar a distintos algoritmos:
\begin{itemize}
\item{Mayor grado del nodo}
\item{Menor grado del nodo}
\alert<3>{\item{Mayor grado de saturación}}
\end{itemize}
}

\end{frame}

\begin{frame}{DSatur}

La variante que utiliza el mayor grado de saturación, \textsc{DSatur}, es una de las que mejores tiempos logra. 

\uncover<2->{Si bien es un algoritmo exacto, limitamos su ejecución a una determinada cantidad de tiempo para usarlo como heurística, pues arroja soluciones muy buenas en poco tiempo.}

\uncover<3->{Puede generalizarse para coloreo particionado según distintos criterios:
\begin{itemize}
\alert<4>{\item{\textbf{Nodo más sencillo:} de cada partición sin colorear, se toma el nodo de menor grado de saturación, luego se elige entre ellos el de mayor grado.}}
\alert<5>{\item{\textbf{Partición más difícil:} se determina cuál es la partición aún no coloreada más difícil según distintos criterios, y de ella se elige el nodo de menor grado de saturación.}}
\end{itemize}
}

\end{frame}

\begin{frame}{DSatur Particionado}

Comparamos estos criterios en corridas de un minuto sobre grafos de distinta densidad:
\includechart{chartdsatur.png}

\end{frame} 

\begin{frame}{Heurística inicial}

Teniendo definida la variante de DSatur a utilizar, la aplicamos como heurística inicial, ejecutando por 5 segundos.
\vskip 3pt
Esto no sólo provee una solución inicial para el algoritmo, que actúa como cota superior desde el principio del árbol, sino que también acota considerablemente la cantidad de variables y restricciones. 
\vskip 3pt
\uncover<2->{
Sea $\alert<3>{\chi_0}$ la solución de la heurística inicial,
\begin{align*}
x_{ij} \quad &1 \leq i \leq |V|,\; 1 \leq j \leq \alt<2>{|P|}{\alert{\chi_0}} \\
w_{j} \quad &1 \leq j \leq \alt<2>{|P|}{\alert{\chi_0}}
\end{align*}}
\uncover<3->{Por cada color que no se utilice en la solución inicial, se tienen $|V|+1$ variables menos.}

\end{frame}

\begin{frame}{Heurística primal}

Dada una solución fraccionaria, fijamos en $1$ aquellas variables $x_{ij}$ mayores a determinado valor. A partir de ese coloreo parcial, utilizamos DSatur para construir una solución entera válida.

\uncover<2->{
\begin{block}{}
Si bien la heurística primal funciona correctamente, la inicial arroja un resultado demasiado cerca del óptimo, lo cual hace que la heurística primal sea incapaz de mejorar el resultado inicial en la mayoría de los casos. Sólo en grafos muy densos logra una mejora respecto de la solución inicial.
\end{block}
}

\end{frame}
