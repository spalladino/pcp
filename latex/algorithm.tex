%!TEX root = pcp.tex

\section{Branch and Cut}
\label{sec:bnc}

In this section we will present the implemented branch-and-cut algorithm, including initial heuristic, branching strategies, separation algorithms and primal heuristics.

\TODO{Short explanation of the structure of a branch and cut algorithm}

\subsection{Preprocessing}

The first step in solving a \PCP instance consists in preprocessing the graph, applying all of the following rules until no more modifications are made to the graph:

\begin{enumerate}
	\item{As an initial step, every edge with both nodes within the same partition is removed. Since only one node is colored per partition, there can be no color conflicts between nodes of the same partition, and all edges connecting them can be removed, in order to greatly reduce the size of the graph and the number of adjacency restrictions generated.}
	\item{Partitions containing isolated nodes can be completely removed from the graph, as any isolated node can be trivially colored using the lowest possible label, and coloring a single node within a partition marks the whole partition as colored, therefore allowing us to completely remove it.}
	\item{Neighbourhood inclusion criteria is applied within a single partition in order to remove higher-order nodes. Let $u,v$ be two different nodes in a partition $P_k$, if $N(u) \subseteq N(v)$, then we can remove node $v$ from the graph. This criteria is valid as only one node per partition needs to be colored, and any valid coloring that assigns color $j_0$ to node $v$, can be modified to assign color $j_0$ to node $u$ instead, still satisfying all color constraints. Intuitively, we are removing \textit{difficult} nodes from a partition when we find an easier one to substitute it. See figure \ref{fig:neighbourinclusion} for an example.}
	
\begin{figure}[h]
	\label{fig:neighbourinclusion}
	\centering
	\begin{tikzpicture} 
		[includer/.style= {minimum size=3mm,thick,circle,draw=red!75,fill=red!20}, 
		included/.style= {minimum size=3mm,thick,circle,draw=green!75,fill=green!20}, 
		other/.style= {minimum size=3mm,thick,circle,draw=black,fill=black}, 
		transition/.style={thick,draw=black,fill=black!20}] 
		
		\node[other] (n3) at ( -1,3) {}; 
		\node[other] (n4) at ( 0,3) {}; 
		\node[other] (n5) at ( 1,3) {}; 
		\node[other] (n6) at ( 2,3) {}; 
		
		\node[includer] (n1) at ( 0,0) {$v_1$}
			edge [-]	(n3)
			edge [-]	(n4)
			edge [-]	(n5)
			edge [-]	(n6)
		;
		
		\node[included] (n2) at ( 1,0) {$v_2$}
			edge [-]	(n4)
			edge [-]	(n5)
			edge [-]	(n6)
		;
		
	
		\begin{pgfonlayer}{background} 
			\node [fill=black!10,circle,fit=(n1) (n2),label=350:$P_1$] {}; 
		\end{pgfonlayer} 
		
	\end{tikzpicture} 
\caption{Neighbourhood inclusion example: node $v_1$ will be removed from the graph as its neighbourhood completely contains $N(v_2)$.}
\end{figure}
	
	\item{A lower bound for the chromatic number of the graph is obtained by finding a maximal clique in the partitions graph $G'$. Finding a clique of size $\omega$ in $G'$ implies that at least $\omega$ different colors are needed for coloring the partitions graph, and the same lower bound clearly holds for $G$. All partitions in the clique will have their colors fixed to $1,\ldots,\omega$ in order to reduce the number of possible colorings, since each of them must be painted using a different color.}
	\item{As in step 2, partitions that contain at least one node with degree less than the lower bound found in the previous step are removed. A node with strictly less than $\omega$ neighbours can be assigned a color among $1,\ldots,\omega$, knowing that no color conflicts will occur; and since there are already $\omega$ colors required, the chromatic number is not increased by that assignment, and therefore the node can be discarded.}
\end{enumerate}

Last 3 steps are performed until no more changes are made to the graph. The resulting largest clique found is used to fix the colors of the partitions included in the clique. 

Every step is processed by brute force, since their running time is polynomial in the size of the graph, except for step 4 for which we use the following algorithm.

\subsubsection*{Partitions graph clique detection}

To find the maximum clique in the partitions graph we use a simple backtracking algorithm. Since the running time of this algorithm can be excessive for a preprocessing step, we bound the running time of this algorithm to five seconds; however, the algorithm usually ends much sooner, as the partitions graph is not only smaller but also much less dense than the original graph. 

In case the time bound is reached, the best solution found so far is returned. As the backtracking uses DFS to explore all possible solutions, a reasonably good solution is generated early in the algorithm, therefore interrupting its execution still yields a valid result.

Starting with an initial node, the algorithm keeps a list of valid candidates for the clique, which is updated on each iteration by removing all nodes that are not adjacent to the current clique. Keeping both the candidates list and all adjacency lists sorted by degree allows both faster computing of the intersection between these lists and produces better initial solutions that can be used to prune other solutions later.

\begin{algorithm}
\caption{Finding a maximum clique in a simple graph $G=<V,E>$}
\label{alg:gpclique}

\begin{algorithmic}

\STATE sort all nodes and adjacency lists descendingly by degree

\FORALL{initial node $v$ in $V$}
	\STATE initialize \textit{clique} with node $v$
	\STATE initialize \textit{candidates} with $N(v)$
	\CALL clique 
\ENDFOR

\PROC{clique}
	\IF{\textit{candidates} is empty}
		\STATE update \textit{best} solution if current \textit{clique} is better
	\ELSIF{\textit{clique}.size + \textit{candidates}.size $\leq$ \textit{best}.size}
		\STATE prune current tree
	\ELSE
		\STATE pop node $u$ from \textit{candidates} and add it to \textit{clique}
		\STATE intersect \textit{candidates} with $N(u)$ and store \textit{removed} nodes
		\CALL clique
		\STATE remove node $u$ from \textit{clique}
		\STATE add \textit{removed} nodes back to \textit{candidates} 
		\CALL clique
	\ENDIF
\ENDPROC

\end{algorithmic}
\end{algorithm} 

\subsection{Initial heuristic}

A good initial heuristic solution gives an upper bound on the solution, eliminates a large number of variables and restrictions in the model, and can be used as an initial incumbent solution for the branch and cut algorithm. 

In order to generate this solution, we use the modification of the \textsc{dsatur} algorithm for partitioned graphs presented in \ref{sec:heur}. Since the algorithm generates an implicit enumeration of all possible colorings, its running time is bounded to five seconds. The coloring of the partitions in the clique $K$ is fixed to labels $1, \ldots, \omega$ in order to reduce the solutions set.

\subsection{Initialization}

Using the initial solution as an upper bound $\hat{\chi}$ for the chromatic number, it is possible to eliminate all $x_{ij}$ and $w_j$ variables for which  $j > \hat{\chi}$, therefore greatly reducing the number of involved variables and restrictions in the model.

Another optimization is to fix the colors for all partitions involved in the clique $K$ found during the preprocessing stage. Since it is not possible to determine which node within the partition is to be colored, we simply set to zero all $x_{ij}$ variables for nodes within the partitions that use a different color than the one assigned. Formally, let $K = \{ P_{K_1}, \ldots, P_{K_\omega} \}$ be the initial clique, then:
\begin{align*}
x_{ij} = 0 \quad &\forall i \in K[l],\ \forall 1 \leq l \leq \omega,\ \forall j \neq l \\
w_j = 1 \quad &\forall 1 \leq j \leq \omega
\end{align*}

Also, in case the partition being fixed to a color $j_k$ has a single node in it, then variable $x_{ij_0}$, where $i$ is the single node in the partition, is fixed to $1$.

Another bound based on nodes degree is imposed. A node $v$ of partition degree $\delta_P(v)$ can always be colored with a label $j_k$ such that $1 \leq j_k \leq \delta_P(v) + 1$, since it will be neighbour to at most $\delta_P(v)$ different colors, therefore any set of $\delta_P(v) + 1$ colors contains at least one valid label that does not generate color conflicts.  
\begin{equation*}
x_{ij} = 0 \quad \forall i \in V,\ \forall 1 \leq j \leq \delta_P(v) + 1 \\
\end{equation*}

Finally, in case minimum partition index breaking symmetry restrictions (\ref{eqn:minlabel}) are being used, this is, the color with the lowest label is assigned to the color class containing the partition with the lowest index, another bound can be imposed on $x_ij$ variables. Since in the worst case all partitions will have a different color, then a partition with index $i$ will never be colored with label greater than $i$. Therefore, the following bound is imposed:
\begin{equation*}
x_{ij} = 0 \quad \forall P_k \in P,\ \forall i \in P_k,\ \forall j > k \\
\end{equation*}

\subsection{Cuts separation}

For each family of valid inequalities listed in \ref{sec:ineqs}, an heuristic is implemented to find a set of valid inequalities being violated in a given linear relaxation of the model. Note that in most cases, finding all violated inequalities in a solution is NP, so heuristic procedures must be applied. 

Since these algorithms are applied frequently during the branch and cut tree, it is imperative that their running time is as fast as possible, in order to add a low overhead to the whole algorithm.

\subsubsection*{Extended clique cuts}

Separation of extended clique cuts (\ref{ineq:extendedclique}) is done using a very similar algorithm to \ref{alg:gpclique}, adapted to partitioned graphs and without backtracking to improve running time. The algorithm is executed once for each color, and nodes are sorted based not on their degree but on their $x_{ij}$ value in the current solution.

For each initial node, a clique is constructed until the corresponding inequality is broken, and extended to up to $\kappa$ maximal cliques using backtracking, making use of the \textit{candidates} collection (note that in this case, \textit{candidates} is initialized with not only the initial node's neighbours, but also with all the nodes in its partition). In case no clique breaking the inequality is found, the next initial node is picked.

In order to avoid exploring the same solution space multiple times for different initial nodes, restrictions on how many times a node or an edge can be visited are applied. The resulting algorithm is presented in \ref{alg:sep:extclique}.

\begin{algorithm}
\label{alg:sep:extclique}

\begin{algorithmic}

\FORALL{color $j$ such that $w_j \geq \mu$}
\STATE sort all nodes and adjacency lists descendingly by $x_{ij}$ value
 
\FORALL{initial node $v$ in $V$}
	\STATE initialize \textit{clique} with node $v$
	\STATE initialize \textit{candidates} with $N(v) \cup P(v)$

	\WHILE{\textit{candidates} is not empty}
		\IF{current clique breaks inequality}
			\FORALL{maximal cliques $K$ containing \textit{clique} up to $\kappa$}
				\STATE add extended clique cut using $K$ and color $j$ 
			\ENDFOR
			\STATE continue with next initial node
		\ELSIF{next candidate $u$ can be used}
			\STATE add $u$ to \textit{clique} and remove it from \textit{candidates} 
			\STATE remove nodes not adjacent to $u$ from \textit{candidates} 
		\ELSE
			\STATE remove $u$ from \textit{candidates}
		\ENDIF
	\ENDWHILE
		
\ENDFOR
\ENDFOR

\caption{Separation algorithm for extended clique cuts}

\end{algorithmic}
\end{algorithm} 

\subsubsection*{Component independent set inequalities}

Inequalities component hole \ref{ineq:chole} and component path \ref{ineq:cpath} are separated within the same procedure using a greedy heuristic. In a similar fashion to algorithm \ref{alg:sep:extclique}, for every color the graph is sorted according to $x_{ij}$ values, and for each initial node a component path or hole is greedily constructed. Once again, bounds for a maximum number of visits on each node are imposed, thus rejecting nodes with a certain number of visits or belonging to a partition already in the path, since this would violate the \textit{component} property.

On every iteration the most promising node is added to the path being built. In case this node is adjacent to a node already in the path (thus generating a hole), it is added only if it violates the corresponding inequality, otherwise, the next candidate is picked, and so forth. Algorithm \ref{alg:sep:ciset} resumes this process.

\begin{algorithm}
\label{alg:sep:ciset}

\begin{algorithmic}

\FORALL{color $j$ such that $w_j \geq \mu$}
\STATE sort all nodes and adjacency lists descendingly by $x_{ij}$ value
 
\FORALL{initial node $v$ in $V$}
	\STATE initialize \textit{path} with node $v$

	\LOOP
		\FORALL{valid node $u$ adjacent to last node in the path}
			\IF{$u$ is adjacent to a previous node $w$ in the path}
				\IF{hole $H=[u,\ldots,w]$ violates inequality \ref{ineq:chole}}
					\STATE add component hole inequality with hole $H$ and color $j$
					\STATE continue with next initial node
				\ENDIF
			\ELSE
				\STATE add node $u$ to \textit{path}	
				\IF{current \textit{path} breaks inequality \ref{ineq:cpath}}
					\STATE add component path inequality with \textit{path} and color $j$
					\STATE continue with next initial node
				\ENDIF
			\ENDIF
		\ENDFOR
	\ENDLOOP
\ENDFOR

\ENDFOR

\caption{Separation algorithm for component independent set cuts}

\end{algorithmic}
\end{algorithm}

As an alternative to the previous algorithm, we also implemented the hole detection algorithm presented in \cite{nikolopoulos2004hole}. We adapted the algorithm presented in the paper to reject a node if it belongs to a partition already in the path, therefore exploring only component holes; and tested this implementation against the previous one in section \ref{sec:results}.

\subsubsection*{Partitions graph independent set inequalities}

For both path and hole inequalities (\ref{ineq:gpiset}) over the partitions graph $G'$, algorithms equivalent to the ones used for component independent sets are applied as separation heuristics, without the checks for ensuring that every node is on a different partition.

Graph $G'$ is constructed once at the beginning of the branch and cut and is then used as the input for these heuristics. Since there are no $x_{ij}$ variables to use for sorting the nodes of the graph, the value $\sum_{i \in P_k} x_{ij}$ is used for each partition $P_k$, this is, the sum of the partition's nodes' values.

\subsubsection*{Block color inequalities}

Block color inequalities (\ref{ineq:blockcp}) are explored using brute force, since there are no more than $c \times q$ of them, and checking whether they are violated or not can be performed fast enough.

Alternatively, they can be added initially to the cut pool provided by the branch and cut framework, instead of manually checking them at each cuts iteration.

\subsection{Branching strategies}

After each node is processed in the branch and cut tree is processed, two new child nodes are created by subdividing the problem in two easier subproblems; this is usually done by \textit{branching} on a certain variable. Usually, in the case of binary variables, a variable $x$ with a fractional value in the relaxation is chosen, and the two subproblems are created by fixing $x = 0$ and $x = 1$ and re-processing. Alternatively, bounds on expressions, instead of on variables, can be set.

Choosing which variable to branch on, and what bounds are implied within each branch, is part of what is called the branching strategy. 

\subsubsection*{Static priorities}

The simplest way to choose which variable to branch on is to set at the beginning of the execution which variables should be preferred, this is, assign a priority to each $x_{ij}$ which will be used to pick the branching variable when necessary. We experimented in section \ref{subsec:resultsbranching} with combinations of the following criteria for selecting variable $x_{ij}$:

\begin{itemize}
\item{The number of partitions adjacent to node $i$}
\item{The size of the partition containing node $i$}
\item{The label of color $j$}
\end{itemize}

Using this criteria has the huge drawback that no information regarding the actual value of the $x_{ij}$ variable is used, so these priorities are to be used in combination with another strategy as a tie-breaker.

\subsubsection*{Fractional values}

A common practice is to pick the most fractional variable to branch on. We determine such variable as:
\[
\min_{x_{ij}} \{ |x_{ij} - 0.5| \}
\]

In case of a tie, we use the static priority set for the variables to determine which one use to branch on. We also tested in section \ref{subsec:resultsbranching} using the opposite criteria, this is, branching on the less fractional value, excluding those variables with already integral values.

This is a common branching technique, but does not exploit any particular feature of the problem being studied.

\subsubsection*{Degree of saturation}

A branching strategy specifically related to the partitioned coloring problem is to branch on a node with the highest degree of saturation. Since these nodes are usually the most difficult ones to handle, it makes sense to fix their values as early as possible in the branch and cut tree.

This criteria for picking the branching variable requires first to compute an approximate degree of saturation of every node and choosing the one with the largest value, $i^*$, in order to obtain a set of candidate variables $x_{i^*j_0}, x_{i^*j_1}, \ldots, x_{i^*j_c}$ (once again, ties are broken using the already defined priorities).

Since the only available values are those of the fractional solution, we color one node in each partition using the largest value within the partition and neighbours: this is, for every node $i$ and color $j$ combination, if the value $x_{ij}$ is larger than all of its neighbours and nodes in the same partition, as well as larger than an arbitrary lower bound (we set $0.7$), we assign color $j$ to node $i$. Note that some partitions might be left uncolored, in this case they will not contribute to the degree of saturation of their neighbours.

\[
v_i \leftarrow j \text{ if } x_{ij} > 0.7 \wedge x_{ij} > x_{kj} \forall k \in N(i) \cup P(i)
\]

From the mentioned set of candidates $x_{i^*j_0}, x_{i^*j_1}, \ldots, x_{i^*j_c}$, the variable with the highest value is chosen to branch on. Overall, we are branching on the node with the highest degree of saturation, fixing it to the most probable color it has assigned in the fractional solution.

\subsubsection*{Implied bounds}

When manually specifying the branch variable and creating the two child nodes by fixing that variable to either zero or one, it is also possible to fix more variables that would be affected by the value assigned to the first one.

Regardless of the branching variable, it is possible to fix all color variables $w_j$ to $1$ for $j = 1,\ldots,\ceil{z}$, where $z$ is the value of the objective function of the current node's relaxation. For example, if the sum of all $w_j$ variables is $5.3$, which is a lower bound on the chromatic number, we can be sure that at least $6$ different colors are needed to color the graph, and therefore all $w_1,\ldots,w_6$ can be set to $1$.

When branching down on the selected variable\footnote{Fixing the branch variable's value to 0.}, there are no more logical implications than the previous one that can be used to bound more variables. This is easy to see since setting an $x_{ij}$ variable to zero implies that a certain color will not be used for a certain node, but does not grant any information on which node on the partition \textit{will} be colored and with \textit{which} color.

Branching up, on the other hand, provides much more information. Whenever a variable $x_{i^*j^*}$ is set to $1$, this is, node $i^*$ in partition $P(i^*)$ is assigned color $j^*$, allows us to specify for that branch the following conditions:

\begin{itemize}
\item Every color-node combination in partition $P(i^*)$ can be set to zero, as only one node must be assigned only one color in the partition.
\[
x_{ij} = 0 \quad \forall i \in P(i^*),\ \forall j \in C,\ i \neq i^* \vee j \neq j^*
\]

\item Every node adjacent to $i^*$ cannot use color $j^*$ in order to avoid color conflicts.
\[
x_{ij^*} = 0 \quad \forall i \in N(i^*)
\]
\end{itemize}